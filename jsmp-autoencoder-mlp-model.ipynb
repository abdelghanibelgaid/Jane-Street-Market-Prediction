{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries & Load Datasets","metadata":{}},{"cell_type":"code","source":"import sys, os, io, gc\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport janestreet\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.layers import Input, BatchNormalization, Dense, Dropout, Concatenate, Lambda, Activation, GaussianNoise\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow_addons.optimizers import RectifiedAdam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(\"Setup Complete\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/jane-street-market-prediction/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_memory_usage(df):\n    \"\"\" \n    iterate through all the columns of a dataframe and \n    modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage of dataframe is {:.2f}' \n                     'MB').format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max <\\\n                  np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max <\\\n                   np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max <\\\n                   np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max <\\\n                   np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max <\\\n                   np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max <\\\n                   np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage after optimization is: {:.2f}' \n                              'MB').format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \n                                             / start_mem))\n    \n    return df\n\ndef percentage_missing_values(df):\n    missing_values_count = df.isnull().sum()\n    total_cells = np.product(df.shape)\n    total_missing = missing_values_count.sum()\n    print (\"Percentage of Missing Data = \",(total_missing/total_cells) * 100,\"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"features = [c for c in train.columns if 'feature' in c]\nresp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.query('date > 85').reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.fillna(train.mean(), inplace=True)\nf_mean = np.mean(train[features[1:]].values,axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train['weight'] != 0]\ntrain['action'] = ((train['resp'].values) > 0).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train[features[1:]] = train[features[1:]].fillna(train[features[1:]].mean())\n# train['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_memory_usage(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train Size: ',train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train.loc[:, train .columns.str.contains('feature')]\ny_train = np.stack([(train[c]>0).astype(int) for c in resp_cols]).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoded MLP","metadata":{}},{"cell_type":"markdown","source":"## Configuration Parameters","metadata":{}},{"cell_type":"code","source":"SEED=42\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = len(features)\nnum_labels = 5\nnoise = 0.1\nhidden_units = [150, 150, 150]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\nepochs = 200\nbatch_size = 5000\nvalidation_split = 0\nth = 0.503","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Autoencoder","metadata":{}},{"cell_type":"code","source":"def create_autoencoder(num_columns, num_labels, noise):\n    inp = Input(shape=(num_columns,))\n    encoded = BatchNormalization()(inp)\n    encoded = GaussianNoise(noise)(encoded)\n    encoded = Dense(64, activation='relu')(encoded)\n    \n    decoded = Dropout(0.2)(encoded)\n    decoded = Dense(num_columns, name='decoded')(decoded)\n    \n    x = Dense(32, activation='relu')(decoded)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    x = Dense(num_labels, activation='sigmoid', name='label_output')(x)\n    \n    encoder = Model(inputs=inp, outputs=encoded)\n    autoencoder = Model(inputs=inp, outputs=[decoded,x])\n    autoencoder.compile(\n        optimizer=RectifiedAdam(learning_rate=learning_rate),\n        loss={'decoded':'mse', 'label_output':'binary_crossentropy'})\n    return autoencoder, encoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder, encoder = create_autoencoder(num_columns, num_labels, noise)\nautoencoder.fit(X_train, (X_train, y_train),\n               epochs = epochs,\n               batch_size = batch_size,\n               validation_split=validation_split,\n               callbacks=[EarlyStopping('val_loss', patience=10, restore_best_weights=True)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.save_weights('./encoder.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP","metadata":{}},{"cell_type":"code","source":"def mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate, encoder):\n    inp = Input(shape=(num_columns,))\n    \n    x = encoder(inp)\n    x = Concatenate()([x, inp])\n    \n    x = BatchNormalization()(inp)\n    x = Dropout(dropout_rates[0])(x)\n    \n    for i in range(len(hidden_units)):\n        x = Dense(hidden_units[i])(x)\n        x = BatchNormalization()(x)\n        x = Activation(tf.keras.activations.relu)(x) #swish\n        x = Dropout(dropout_rates[i+1])(x)\n    \n    x = Dense(num_labels)(x)\n    out = Activation('sigmoid')(x)\n    \n    model = Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=RectifiedAdam(learning_rate=learning_rate),\n        loss=BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name='AUC'))\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate, encoder)\nclf.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.save(f'model.h5')\nmodels = []\nmodels.append(clf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"env = janestreet.make_env()\niter_test = env.iter_test()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test_df, prediction_df) in tqdm(iter_test):\n    if test_df['weight'].item() > 0:\n        test_df = test_df.loc[:, features].values\n        if np.isnan(test_df[:, 1:].sum()):\n            test_df[:, 1:] = np.nan_to_num(test_df[:, 1:]) + np.isnan(test_df[:, 1:]) * f_mean\n        pred = np.mean([model(test_df, training = False).numpy() for model in models], axis=0)\n        pred = np.median(pred)\n        prediction_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        prediction_df.action = 0\n    env.predict(prediction_df)\nprint('Infrence is Completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}